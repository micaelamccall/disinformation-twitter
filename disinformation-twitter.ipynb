{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disinformation on twitter\n",
    "Iranian state-sponsored campaigns aimed at Venezuela\n",
    "\n",
    "\n",
    "## Step 1: Data Cleaning\n",
    "#### This chunk of code just imports some programs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This lets the program know which is the current folder and which is the folder with the data in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_ROOT_DIR = os.getcwd()\n",
    "\n",
    "DATA_PATH = os.path.join(PROJ_ROOT_DIR, \"csv\")\n",
    "if not os.path.isdir(DATA_PATH):  \n",
    "    os.makedirs(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.) Combine all the data files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_twitter_data():\n",
    "    \"\"\"\n",
    "    A function to load data from data folder\n",
    "    \"\"\"\n",
    "    # List of files\n",
    "    files = [f for f in os.listdir(DATA_PATH) if f.endswith(\".csv\")]\n",
    "    \n",
    "    # List of data frames\n",
    "    file_list = []\n",
    "    \n",
    "    # Append each data frame in files to the file_list\n",
    "    for filename in files:\n",
    "        df = pd.read_csv(os.path.join(DATA_PATH, filename), low_memory=False)\n",
    "        file_list.append(df)\n",
    "        \n",
    "    # Concatenate all the news data frames\n",
    "    df_full = pd.concat(file_list, join='outer', sort = True).drop_duplicates().reset_index().drop(columns='index')\n",
    "    \n",
    "    return df_full\n",
    "\n",
    "tweets = load_twitter_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.) Select only the columns we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_display_name</th>\n",
       "      <th>user_reported_location</th>\n",
       "      <th>account_language</th>\n",
       "      <th>tweet_language</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_time</th>\n",
       "      <th>urls</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>akhonfellah</td>\n",
       "      <td>⁦🇮🇷⁩أخٌ‌في‌الله</td>\n",
       "      <td>Iran</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>one person followed me // automatically checke...</td>\n",
       "      <td>2017-01-11 05:23</td>\n",
       "      <td>['http://fllwrs.com']</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>akhonfellah</td>\n",
       "      <td>⁦🇮🇷⁩أخٌ‌في‌الله</td>\n",
       "      <td>Iran</td>\n",
       "      <td>en</td>\n",
       "      <td>fa</td>\n",
       "      <td>#IDFTerrorists\\nحماسه تروریستهای اسرائیلی http...</td>\n",
       "      <td>2018-05-26 00:48</td>\n",
       "      <td>[]</td>\n",
       "      <td>['IDFTerrorists']</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>akhonfellah</td>\n",
       "      <td>⁦🇮🇷⁩أخٌ‌في‌الله</td>\n",
       "      <td>Iran</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>Stop war on Yemen hospitals\\n#ShameOnUN\\n#Yemen</td>\n",
       "      <td>2018-06-16 20:06</td>\n",
       "      <td>[]</td>\n",
       "      <td>['ShameOnUN', 'Yemen']</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>akhonfellah</td>\n",
       "      <td>⁦🇮🇷⁩أخٌ‌في‌الله</td>\n",
       "      <td>Iran</td>\n",
       "      <td>en</td>\n",
       "      <td>fa</td>\n",
       "      <td>لبیک یا فقیه\\n#مجزرة_الدراز https://t.co/nKfQW...</td>\n",
       "      <td>2018-05-23 18:22</td>\n",
       "      <td>[]</td>\n",
       "      <td>['مجزرة_الدراز']</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>akhonfellah</td>\n",
       "      <td>⁦🇮🇷⁩أخٌ‌في‌الله</td>\n",
       "      <td>Iran</td>\n",
       "      <td>en</td>\n",
       "      <td>fa</td>\n",
       "      <td>اینجا تل ابیب است\\nاینها اسراییلیهایی هستند که...</td>\n",
       "      <td>2019-01-28 16:56</td>\n",
       "      <td>[]</td>\n",
       "      <td>['زندگی_سگی_اسرائیلیها']</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>akhonfellah</td>\n",
       "      <td>⁦🇮🇷⁩أخٌ‌في‌الله</td>\n",
       "      <td>Iran</td>\n",
       "      <td>en</td>\n",
       "      <td>ar</td>\n",
       "      <td>وامروز هم ....\\n#زندگی_سگی_اسرائیلیها https://...</td>\n",
       "      <td>2018-09-07 10:42</td>\n",
       "      <td>[]</td>\n",
       "      <td>['زندگی_سگی_اسرائیلیها']</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>akhonfellah</td>\n",
       "      <td>⁦🇮🇷⁩أخٌ‌في‌الله</td>\n",
       "      <td>Iran</td>\n",
       "      <td>en</td>\n",
       "      <td>fa</td>\n",
       "      <td>حکمت ثابت موندن اسم ماههای قمری بعد از تغییر ز...</td>\n",
       "      <td>2017-11-19 19:40</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>akhonfellah</td>\n",
       "      <td>⁦🇮🇷⁩أخٌ‌في‌الله</td>\n",
       "      <td>Iran</td>\n",
       "      <td>en</td>\n",
       "      <td>fa</td>\n",
       "      <td>جمله ای که سیدحسن امشب گفت در مورد انقلاب اسلا...</td>\n",
       "      <td>2019-02-06 18:26</td>\n",
       "      <td>[]</td>\n",
       "      <td>['إن_مع_الصبر_نصرا']</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>akhonfellah</td>\n",
       "      <td>⁦🇮🇷⁩أخٌ‌في‌الله</td>\n",
       "      <td>Iran</td>\n",
       "      <td>en</td>\n",
       "      <td>fa</td>\n",
       "      <td>بشنوید مدح حاج محمودآقوی کریمی رو با لهجه شیرا...</td>\n",
       "      <td>2017-08-04 12:25</td>\n",
       "      <td>['https://twitter.com/khanisadiq/status/893438...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>akhonfellah</td>\n",
       "      <td>⁦🇮🇷⁩أخٌ‌في‌الله</td>\n",
       "      <td>Iran</td>\n",
       "      <td>en</td>\n",
       "      <td>ar</td>\n",
       "      <td>RT @awadazeinab1: كم ساعة مع ابني بالمستشفى شف...</td>\n",
       "      <td>2019-01-25 17:48</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_screen_name user_display_name user_reported_location account_language  \\\n",
       "0      akhonfellah   ⁦🇮🇷⁩أخٌ‌في‌الله                   Iran               en   \n",
       "1      akhonfellah   ⁦🇮🇷⁩أخٌ‌في‌الله                   Iran               en   \n",
       "2      akhonfellah   ⁦🇮🇷⁩أخٌ‌في‌الله                   Iran               en   \n",
       "3      akhonfellah   ⁦🇮🇷⁩أخٌ‌في‌الله                   Iran               en   \n",
       "4      akhonfellah   ⁦🇮🇷⁩أخٌ‌في‌الله                   Iran               en   \n",
       "5      akhonfellah   ⁦🇮🇷⁩أخٌ‌في‌الله                   Iran               en   \n",
       "6      akhonfellah   ⁦🇮🇷⁩أخٌ‌في‌الله                   Iran               en   \n",
       "7      akhonfellah   ⁦🇮🇷⁩أخٌ‌في‌الله                   Iran               en   \n",
       "8      akhonfellah   ⁦🇮🇷⁩أخٌ‌في‌الله                   Iran               en   \n",
       "9      akhonfellah   ⁦🇮🇷⁩أخٌ‌في‌الله                   Iran               en   \n",
       "\n",
       "  tweet_language                                         tweet_text  \\\n",
       "0             en  one person followed me // automatically checke...   \n",
       "1             fa  #IDFTerrorists\\nحماسه تروریستهای اسرائیلی http...   \n",
       "2             en    Stop war on Yemen hospitals\\n#ShameOnUN\\n#Yemen   \n",
       "3             fa  لبیک یا فقیه\\n#مجزرة_الدراز https://t.co/nKfQW...   \n",
       "4             fa  اینجا تل ابیب است\\nاینها اسراییلیهایی هستند که...   \n",
       "5             ar  وامروز هم ....\\n#زندگی_سگی_اسرائیلیها https://...   \n",
       "6             fa  حکمت ثابت موندن اسم ماههای قمری بعد از تغییر ز...   \n",
       "7             fa  جمله ای که سیدحسن امشب گفت در مورد انقلاب اسلا...   \n",
       "8             fa  بشنوید مدح حاج محمودآقوی کریمی رو با لهجه شیرا...   \n",
       "9             ar  RT @awadazeinab1: كم ساعة مع ابني بالمستشفى شف...   \n",
       "\n",
       "         tweet_time                                               urls  \\\n",
       "0  2017-01-11 05:23                              ['http://fllwrs.com']   \n",
       "1  2018-05-26 00:48                                                 []   \n",
       "2  2018-06-16 20:06                                                 []   \n",
       "3  2018-05-23 18:22                                                 []   \n",
       "4  2019-01-28 16:56                                                 []   \n",
       "5  2018-09-07 10:42                                                 []   \n",
       "6  2017-11-19 19:40                                                 []   \n",
       "7  2019-02-06 18:26                                                 []   \n",
       "8  2017-08-04 12:25  ['https://twitter.com/khanisadiq/status/893438...   \n",
       "9  2019-01-25 17:48                                                 []   \n",
       "\n",
       "                   hashtags  is_retweet  \n",
       "0                        []       False  \n",
       "1         ['IDFTerrorists']       False  \n",
       "2    ['ShameOnUN', 'Yemen']       False  \n",
       "3          ['مجزرة_الدراز']       False  \n",
       "4  ['زندگی_سگی_اسرائیلیها']       False  \n",
       "5  ['زندگی_سگی_اسرائیلیها']       False  \n",
       "6                        []       False  \n",
       "7      ['إن_مع_الصبر_نصرا']       False  \n",
       "8                        []       False  \n",
       "9                        []        True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_clean = tweets[['user_screen_name',  'user_display_name', 'user_reported_location', 'account_language', 'tweet_language', 'tweet_text', 'tweet_time', 'urls', 'hashtags', 'is_retweet']]\n",
    "\n",
    "# Top 10 rows of data\n",
    "tweets_clean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c.) Filter Tweets and keeps those that are either \n",
    " - account located in Venezuela\n",
    " - account language Spanish OR\n",
    " - tweet language Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean = tweets_clean[(tweets_clean.user_reported_location == 'Venezuela') | (tweets_clean.account_language == 'es') | (tweets_clean.tweet_language == 'es')].reset_index().drop(columns= ['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d.) Take out Tweets that are set in European and US location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_display_name</th>\n",
       "      <th>user_reported_location</th>\n",
       "      <th>account_language</th>\n",
       "      <th>tweet_language</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_time</th>\n",
       "      <th>urls</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>akhonfellah</td>\n",
       "      <td>⁦🇮🇷⁩أخٌ‌في‌الله</td>\n",
       "      <td>Iran</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>No parallel in history....\\n#Hussain https://t...</td>\n",
       "      <td>2018-09-19 20:04</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Hussain']</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>akhonfellah</td>\n",
       "      <td>⁦🇮🇷⁩أخٌ‌في‌الله</td>\n",
       "      <td>Iran</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>HABIL CAFE😂 https://t.co/5ipZYvYA8X</td>\n",
       "      <td>2017-10-04 03:28</td>\n",
       "      <td>['https://twitter.com/KnowKaduna/status/915295...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Romeo1997er</td>\n",
       "      <td>Romeo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fa</td>\n",
       "      <td>es</td>\n",
       "      <td>RT @countdown2040: Gazans prepare for Hajj\\nht...</td>\n",
       "      <td>2017-08-29 03:17</td>\n",
       "      <td>['http://www.countdown2040.com/ShowGallery/69/']</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kasia36790875</td>\n",
       "      <td>Kasia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fa</td>\n",
       "      <td>es</td>\n",
       "      <td>RT @countdown2040: Abbas sends medical aid to ...</td>\n",
       "      <td>2017-11-18 16:36</td>\n",
       "      <td>['http://www.countdown2040.com/ShowNews/1014/']</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hmn90432381</td>\n",
       "      <td>H.m.n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fa</td>\n",
       "      <td>es</td>\n",
       "      <td>RT @countdown2040: Gazans prepare for Hajj\\nht...</td>\n",
       "      <td>2017-09-24 14:28</td>\n",
       "      <td>['http://www.countdown2040.com/ShowGallery/69/']</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>koInQlW0rKxQPoTuf5BmVjKyTvYJR5JdKeo8spDdrwM=</td>\n",
       "      <td>koInQlW0rKxQPoTuf5BmVjKyTvYJR5JdKeo8spDdrwM=</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fa</td>\n",
       "      <td>es</td>\n",
       "      <td>RT @countdown2040: Abbas sends medical aid to ...</td>\n",
       "      <td>2017-10-30 16:52</td>\n",
       "      <td>['http://www.countdown2040.com/ShowNews/1014/']</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24evm+SfMta5ONKMRjQe1Qj39PdyLGPqMMXl8XYDbg=</td>\n",
       "      <td>24evm+SfMta5ONKMRjQe1Qj39PdyLGPqMMXl8XYDbg=</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>RT @countdown2040: Video: Lana Del Rey Ignores...</td>\n",
       "      <td>2018-08-28 08:33</td>\n",
       "      <td>['http://www.countdown2040.com/ShowMovieList/9...</td>\n",
       "      <td>['GroupPalestine', 'قروب_فلسطيني']</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GP3PzukVFPWVoLtVWTEyy20m2lRZaMaRmN7n0lz7Bg=</td>\n",
       "      <td>GP3PzukVFPWVoLtVWTEyy20m2lRZaMaRmN7n0lz7Bg=</td>\n",
       "      <td>Earth</td>\n",
       "      <td>fa</td>\n",
       "      <td>es</td>\n",
       "      <td>RT @countdown2040: Gazans prepare for Hajj\\nht...</td>\n",
       "      <td>2017-09-28 17:53</td>\n",
       "      <td>['http://www.countdown2040.com/ShowGallery/69/']</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Richard80907</td>\n",
       "      <td>Richard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fa</td>\n",
       "      <td>es</td>\n",
       "      <td>RT @countdown2040: Gazans prepare for Hajj\\nht...</td>\n",
       "      <td>2017-11-05 15:47</td>\n",
       "      <td>['http://www.countdown2040.com/ShowGallery/69/']</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UW2EZRTAv0C7rCy2LOI2SBiYh8IrdwmQAdI7p7yqok=</td>\n",
       "      <td>UW2EZRTAv0C7rCy2LOI2SBiYh8IrdwmQAdI7p7yqok=</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>es</td>\n",
       "      <td>Abbas sends medical aid to Venezuela, sparking...</td>\n",
       "      <td>2017-08-23 08:02</td>\n",
       "      <td>['http://www.UW2EZRTAv0C7rCy2LOI2SBiYh8IrdwmQA...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               user_screen_name  \\\n",
       "0                                   akhonfellah   \n",
       "1                                   akhonfellah   \n",
       "2                                   Romeo1997er   \n",
       "3                                 Kasia36790875   \n",
       "4                                   Hmn90432381   \n",
       "5  koInQlW0rKxQPoTuf5BmVjKyTvYJR5JdKeo8spDdrwM=   \n",
       "6   24evm+SfMta5ONKMRjQe1Qj39PdyLGPqMMXl8XYDbg=   \n",
       "7   GP3PzukVFPWVoLtVWTEyy20m2lRZaMaRmN7n0lz7Bg=   \n",
       "8                                  Richard80907   \n",
       "9   UW2EZRTAv0C7rCy2LOI2SBiYh8IrdwmQAdI7p7yqok=   \n",
       "\n",
       "                              user_display_name user_reported_location  \\\n",
       "0                               ⁦🇮🇷⁩أخٌ‌في‌الله                   Iran   \n",
       "1                               ⁦🇮🇷⁩أخٌ‌في‌الله                   Iran   \n",
       "2                                         Romeo                    NaN   \n",
       "3                                         Kasia                    NaN   \n",
       "4                                         H.m.n                    NaN   \n",
       "5  koInQlW0rKxQPoTuf5BmVjKyTvYJR5JdKeo8spDdrwM=                    NaN   \n",
       "6   24evm+SfMta5ONKMRjQe1Qj39PdyLGPqMMXl8XYDbg=                    NaN   \n",
       "7   GP3PzukVFPWVoLtVWTEyy20m2lRZaMaRmN7n0lz7Bg=                 Earth    \n",
       "8                                       Richard                    NaN   \n",
       "9   UW2EZRTAv0C7rCy2LOI2SBiYh8IrdwmQAdI7p7yqok=                    NaN   \n",
       "\n",
       "  account_language tweet_language  \\\n",
       "0               en             es   \n",
       "1               en             es   \n",
       "2               fa             es   \n",
       "3               fa             es   \n",
       "4               fa             es   \n",
       "5               fa             es   \n",
       "6               en             es   \n",
       "7               fa             es   \n",
       "8               fa             es   \n",
       "9               en             es   \n",
       "\n",
       "                                          tweet_text        tweet_time  \\\n",
       "0  No parallel in history....\\n#Hussain https://t...  2018-09-19 20:04   \n",
       "1                HABIL CAFE😂 https://t.co/5ipZYvYA8X  2017-10-04 03:28   \n",
       "2  RT @countdown2040: Gazans prepare for Hajj\\nht...  2017-08-29 03:17   \n",
       "3  RT @countdown2040: Abbas sends medical aid to ...  2017-11-18 16:36   \n",
       "4  RT @countdown2040: Gazans prepare for Hajj\\nht...  2017-09-24 14:28   \n",
       "5  RT @countdown2040: Abbas sends medical aid to ...  2017-10-30 16:52   \n",
       "6  RT @countdown2040: Video: Lana Del Rey Ignores...  2018-08-28 08:33   \n",
       "7  RT @countdown2040: Gazans prepare for Hajj\\nht...  2017-09-28 17:53   \n",
       "8  RT @countdown2040: Gazans prepare for Hajj\\nht...  2017-11-05 15:47   \n",
       "9  Abbas sends medical aid to Venezuela, sparking...  2017-08-23 08:02   \n",
       "\n",
       "                                                urls  \\\n",
       "0                                                 []   \n",
       "1  ['https://twitter.com/KnowKaduna/status/915295...   \n",
       "2   ['http://www.countdown2040.com/ShowGallery/69/']   \n",
       "3    ['http://www.countdown2040.com/ShowNews/1014/']   \n",
       "4   ['http://www.countdown2040.com/ShowGallery/69/']   \n",
       "5    ['http://www.countdown2040.com/ShowNews/1014/']   \n",
       "6  ['http://www.countdown2040.com/ShowMovieList/9...   \n",
       "7   ['http://www.countdown2040.com/ShowGallery/69/']   \n",
       "8   ['http://www.countdown2040.com/ShowGallery/69/']   \n",
       "9  ['http://www.UW2EZRTAv0C7rCy2LOI2SBiYh8IrdwmQA...   \n",
       "\n",
       "                             hashtags  is_retweet  \n",
       "0                         ['Hussain']       False  \n",
       "1                                  []       False  \n",
       "2                                  []        True  \n",
       "3                                  []        True  \n",
       "4                                  []        True  \n",
       "5                                  []        True  \n",
       "6  ['GroupPalestine', 'قروب_فلسطيني']        True  \n",
       "7                                  []        True  \n",
       "8                                  []        True  \n",
       "9                                  []       False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_clean = tweets_clean[(tweets_clean.user_reported_location != 'London') & (tweets_clean.user_reported_location != 'Manhattan, NY') & (tweets_clean.user_reported_location != 'Brooklyn, NY') & (tweets_clean.user_reported_location != 'Queens, NY') & (tweets_clean.user_reported_location != 'New York, NY') & (tweets_clean.user_reported_location != 'California, USA') & (tweets_clean.user_reported_location != 'New Jersey, USA') &  (tweets_clean.user_reported_location != 'North Holland, The Netherlands') & (tweets_clean.user_reported_location != 'Atlantic City, NJ') & (tweets_clean.user_reported_location != 'Mountain View, CA') & (tweets_clean.user_reported_location != 'New York, USA') & (tweets_clean.user_reported_location != 'Canada') & (tweets_clean.user_reported_location != 'San Francisco, CA') & (tweets_clean.user_reported_location != 'Washington, USA') & (tweets_clean.user_reported_location != 'Washington, DC') & (tweets_clean.user_reported_location != 'España') & (tweets_clean.user_reported_location != 'Germany') & (tweets_clean.user_reported_location != 'Nantes, France') & (tweets_clean.user_reported_location != 'Houston, TX') & (tweets_clean.user_reported_location != 'Texas,San Antonio') & (tweets_clean.user_reported_location != 'Chicago') & (tweets_clean.user_reported_location != 'Atlanta') & (tweets_clean.user_reported_location != 'Washington,Seattle') & (tweets_clean.user_reported_location != 'Fremont, CA') & (tweets_clean.user_reported_location != 'France') & (tweets_clean.user_reported_location != 'England, United Kingdom')  & (tweets_clean.user_reported_location != 'Oregon,Portland')  & (tweets_clean.user_reported_location !='USA')  & (tweets_clean.user_reported_location != 'Florida,Orlando') & (tweets_clean.user_reported_location != 'Califor') & (tweets_clean.user_reported_location !='California,Los Angeles') & (tweets_clean.user_reported_location !='Illinois, USA') & (tweets_clean.user_reported_location !='Arizona,phoenix') & (tweets_clean.user_reported_location !='Pennsylvania,Pittsburgh') & (tweets_clean.user_reported_location !='Pennsylvania,Philadelphia') & (tweets_clean.user_reported_location !='Dallas, TX') ]\n",
    "\n",
    "# Top 10 rows of data\n",
    "tweets_clean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e.) Quality control for Twitter language identification \n",
    "- Import SpaCy, a text-processing package, and load Spanish and English models and Language Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "# Initialize spacy with the SPANISH model\n",
    "sp = spacy.load('es_core_news_sm')\n",
    "sp.add_pipe(LanguageDetector(), name = 'language_detector', last = True)\n",
    "eng = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identify language of each Tweet using SpaCy language identification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(df, content_column):\n",
    "    '''\n",
    "    A function to detect the language in each tweet and add to new row\n",
    "\n",
    "    Argument: a dataframe  and content column\n",
    "    Ouput: same dataframe with a new 'cleaned_content' column\n",
    "    '''\n",
    "\n",
    "    # Initialize list of languages\n",
    "    spacy_language_detection = []\n",
    "\n",
    "    # Call detect the language for each row in the data frame and append to spacy_language_detection list\n",
    "    for row in df[content_column]:\n",
    "        doc = sp(row)\n",
    "        spacy_language_detection.append(doc._.language['language'])\n",
    "\n",
    "    # Append language list to the data frame\n",
    "    df['spacy_language_detection'] = spacy_language_detection\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean = detect_language(df = tweets_clean, content_column = 'tweet_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Keep Tweets that are marked as either Spanish by BOTH Twitter and SpaCy or English by BOTH Twitter and SpaCy.\n",
    "- Separate into 'Spanish' and 'English' datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_tweets = tweets_clean[(tweets_clean.tweet_language == 'es') & (tweets_clean.spacy_language_detection == 'es')]\n",
    "english_tweets = tweets_clean[(tweets_clean.tweet_language == 'en') & (tweets_clean.spacy_language_detection == 'en')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Keyword analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.) Use SpaCy to “clean” each Tweet by removing stop words (very common words that carry little meaning), non alpha-numeric characters, and by reducing each word to it’s lemma or root. \n",
    "This will allow us to create a consistent vocabulary to analyze keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(text_string, language):\n",
    "    '''\n",
    "    A function to clean a string using SpaCy, removing stop-words and non-alphanumeric characters\n",
    "\n",
    "    Argument: a text string and a language ('English' or 'Spanish')\n",
    "    Output: a cleaned string\n",
    "\n",
    "    '''\n",
    "    if language == 'Spanish':\n",
    "    # Parse the text string using the english model initialized earlier\n",
    "        doc = sp(text_string)\n",
    "    elif language == 'English':\n",
    "        doc = eng(text_string)\n",
    "    \n",
    "    # Initialize empty string\n",
    "    clean = []\n",
    "\n",
    "    # Add each token to the list if it is not a stop word, is alphanumeric, and if it's not a pronoun\n",
    "    for token in doc:\n",
    "        \n",
    "        if token.is_alpha == False or token.is_stop == True:\n",
    "            pass\n",
    "        else:\n",
    "            clean.append(token.lemma_)\n",
    "\n",
    "    # Join the list into a string\n",
    "    clean = \" \".join(clean)\n",
    "\n",
    "    return clean\n",
    "\n",
    "def clean_content(df, content_column, language):\n",
    "    '''\n",
    "    A function to clean all the strings in a whole of a corpus\n",
    "\n",
    "    Argument: a dataframe, the name of the column with the content, and a language ('Spanish' or 'English')\n",
    "    Ouput: same dataframe with a new cleaned content column\n",
    "    '''\n",
    "\n",
    "    # Initialize list of cleaned content strings\n",
    "    clean_content= []\n",
    "\n",
    "    # Call clean_string() for each row in the data frame and append to clean_content list\n",
    "    for row in df[content_column]:\n",
    "        clean_content.append(clean_string(row, language))\n",
    "\n",
    "    # Append clean_content list to the data frame\n",
    "    df['lemmatized_tweet_text'] = clean_content\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Here is an example of how this works***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Spanish example: \n",
      "RT @MFloresBazaldua: lo que no ves con tus ojos, no lo inventes con tu boca http://t.co/oOzAorw7Fc\n",
      "\n",
      "Clean exmaple: \n",
      "RT ver ojo inventar boca\n",
      "\n",
      "\n",
      "\n",
      "Raw English example: \n",
      "Great tool. Very easy to use and it does the job very well! I highly recommend it! #BulkFollower https://t.co/SzGtLXW16B\n",
      "\n",
      "Clean exmaple: \n",
      "great tool very easy use job -PRON- highly recommend bulkfollower\n"
     ]
    }
   ],
   "source": [
    "example_sp = spanish_tweets.loc[:,'tweet_text'][0]\n",
    "example_sp_clean = clean_string(example_sp, 'Spanish')\n",
    "print(\"Raw Spanish example: \\n\" + example_sp)\n",
    "print(\"\\nClean exmaple: \\n\" + example_sp_clean)\n",
    "\n",
    "\n",
    "example_eng = english_tweets.loc[:,'tweet_text'][4]\n",
    "example_eng_clean = clean_string(example_eng, \"English\")\n",
    "print(\"\\n\\n\\nRaw English example: \\n\" + example_eng)\n",
    "print(\"\\nClean exmaple: \\n\" + example_eng_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish_tweets = pd.read_csv('xlsx/spanish_tweets.csv', encoding='utf-8-sig', index_col = 0).reset_index().drop(columns='index')\n",
    "english_tweets = pd.read_csv('xlsx/english_tweets.csv', encoding='utf-8-sig', index_col = 0).reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.) Use Scikit-learn ‘CountVectorizer’ package to create word counts for Spanish and English tweets\n",
    "First we create a matrix where each column is a word found in any Tweet and each row is the number of times in occurs in each Tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# only words that appear in more than 5 tweets\n",
    "word_vectorizer = CountVectorizer(encoding='utf-8-sig', analyzer='word', min_df=5, ngram_range=(1,1))\n",
    "word_count_sm = word_vectorizer.fit_transform(spanish_tweets['lemmatized_tweet_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we sum the count of each word over all Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_vectorizer.get_feature_names()\n",
    "word_count_total = word_count_sm.sum(axis=0)\n",
    "word_count_total_df = pd.DataFrame(word_count_total, columns = words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.) Use Scikit-learn ‘CountVectorizer’ package to create phrase counts for Spanish and English tweets\n",
    "We set the length of phrases to be between 3 and 5 words long for one data frame and between 5 to 7 for the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_vectorizer = CountVectorizer(encoding='utf-8-sig', analyzer='word', min_df=5, ngram_range=(5,7))\n",
    "# create matrix where each column is a phrase and each row is a count in each tweet\n",
    "phrase_count_sm = phrase_vectorizer.fit_transform(spanish_tweets['lemmatized_tweet_text'])\n",
    "phrases = phrase_vectorizer.get_feature_names()\n",
    "# sum the count of each phrase over all Tweets\n",
    "phrase_count_total = phrase_count_sm.sum(axis=0)\n",
    "phrase_count_total_df = pd.DataFrame(phrase_count_total, columns = phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
